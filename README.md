# Practical Reinforcement Learning


This repo represents my solutions to the assignments of the course "[Practical Reinforcement Learning](https://www.coursera.org/learn/practical-rl/home/welcome)", offered by HSE university on Coursera: 

1. In [crossentropy_method.ipynb](https://github.com/hsmirzaie/Practical_RL/blob/main/crossentropy_method.ipynb), the [Taxi-v3](https://gym.openai.com/envs/Taxi-v3/}{(Taxi-v3)) problem is solved using Cross-Entropy Method

2. In [deep_crossentropy_method.ipynb](https://github.com/hsmirzaie/Practical_RL/blob/main/deep_crossentropy_method.ipynb), Cross-Entropy Method with Neural Networks  is implemented to solve [CartPole-v0](https://gym.openai.com/envs/CartPole-v0/) and [MountainCar-v0](https://gym.openai.com/envs/MountainCar-v0/) problems

3. In [practice_vi.ipynb](https://github.com/hsmirzaie/Practical_RL/blob/main/practice_vi.ipynb), the tabular Value Iteration method is applied to solve several MDP (Markov Decision Processes) problems

4. In [qlearning.ipynb](https://github.com/hsmirzaie/Practical_RL/blob/main/qlearning.ipynb), the Q-Learning algorithm is implemented to solve tabular (Taxi-v3) and binarized (CartPole-v0) problems

5. In [sarsa.ipynb](https://github.com/hsmirzaie/Practical_RL/blob/main/sarsa.ipynb), the Expected Value SARSA is used to solve an RL problem [CliffWalking](https://github.com/openai/gym/blob/master/gym/envs/toy_text/cliffwalking.py)


6. In [experience_replay.ipynb](https://github.com/hsmirzaie/Practical_RL/blob/main/experience_replay.ipynb), the performance of Q-Learning algorithm in solving Taxi-v3 problem is improved by using Experience Replay technique


7. In [practice_approx_qlearning_pytorch.ipynb](https://github.com/hsmirzaie/Practical_RL/blob/main/practice_approx_qlearning_pytorch.ipynb), neural network is trained (with PyTorch) to solve CartPole-v0 using an approximate version of the Q-learning algorithm
