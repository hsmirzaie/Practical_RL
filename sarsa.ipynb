{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarsa.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxAGRtDDiiuI"
      },
      "source": [
        "## On-policy learning and SARSA\n",
        "\n",
        "_This notebook builds upon `qlearning.ipynb`, or to be exact your implementation of QLearningAgent._\n",
        "\n",
        "The policy we're gonna use is epsilon-greedy policy, where agent takes optimal action with probability $(1-\\epsilon)$, otherwise samples action at random. Note that agent __can__ occasionally sample optimal action during random sampling by pure chance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAx6Icj3iiuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7e8c6c0-069c-4a49-b1d8-f168085aad88"
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week3_model_free/submit.py\n",
        "\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 160815 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbon2cq7iiuM"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqde2IpsiiuN"
      },
      "source": [
        "You can copy your `QLearningAgent` implementation from previous notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfIDvgJ-iiuN"
      },
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, alpha, epsilon, discount, get_legal_actions):\n",
        "        \"\"\"\n",
        "        Q-Learning Agent\n",
        "        based on https://inst.eecs.berkeley.edu/~cs188/sp19/projects.html\n",
        "        Instance variables you have access to\n",
        "          - self.epsilon (exploration prob)\n",
        "          - self.alpha (learning rate)\n",
        "          - self.discount (discount rate aka gamma)\n",
        "\n",
        "        Functions you should use\n",
        "          - self.get_legal_actions(state) {state, hashable -> list of actions, each is hashable}\n",
        "            which returns legal actions for a state\n",
        "          - self.get_qvalue(state,action)\n",
        "            which returns Q(state,action)\n",
        "          - self.set_qvalue(state,action,value)\n",
        "            which sets Q(state,action) := value\n",
        "        !!!Important!!!\n",
        "        Note: please avoid using self._qValues directly. \n",
        "            There's a special self.get_qvalue/set_qvalue for that.\n",
        "        \"\"\"\n",
        "\n",
        "        self.get_legal_actions = get_legal_actions\n",
        "        self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "        self.alpha = alpha\n",
        "        self.epsilon = epsilon\n",
        "        self.discount = discount\n",
        "\n",
        "    def get_qvalue(self, state, action):\n",
        "        \"\"\" Returns Q(state,action) \"\"\"\n",
        "        return self._qvalues[state][action]\n",
        "\n",
        "    def set_qvalue(self, state, action, value):\n",
        "        \"\"\" Sets the Qvalue for [state,action] to the given value \"\"\"\n",
        "        self._qvalues[state][action] = value\n",
        "\n",
        "    #---------------------START OF YOUR CODE---------------------#\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\"\n",
        "        Compute your agent's estimate of V(s) using current q-values\n",
        "        V(s) = max_over_action Q(state,action) over possible actions.\n",
        "        Note: please take into account that q-values can be negative.\n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        if len(possible_actions) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        Qs = []\n",
        "        for action in possible_actions:\n",
        "            Qs.append(self.get_qvalue(state, action))\n",
        "\n",
        "        value = max(Qs)\n",
        "\n",
        "        return value\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        \"\"\"\n",
        "        You should do your Q-Value update here:\n",
        "           Q(s,a) := (1 - alpha) * Q(s,a) + alpha * (r + gamma * V(s'))\n",
        "        \"\"\"\n",
        "\n",
        "        # agent parameters\n",
        "        gamma = self.discount\n",
        "        learning_rate = self.alpha\n",
        "\n",
        "        qvalue = (1-learning_rate)*self.get_qvalue(state, action) + \\\n",
        "                  learning_rate*(reward + gamma*self.get_value(next_state))\n",
        "\n",
        "        self.set_qvalue(state, action, qvalue)\n",
        "\n",
        "    def get_best_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the best action to take in a state (using current q-values). \n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        Qs = []\n",
        "        for action in possible_actions:\n",
        "            Qs.append(self.get_qvalue(state, action))\n",
        "\n",
        "        best_action = possible_actions[np.argmax(Qs)]\n",
        "        \n",
        "\n",
        "        return best_action\n",
        "\n",
        "    def get_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the action to take in the current state, including exploration.  \n",
        "        With probability self.epsilon, we should take a random action.\n",
        "            otherwise - the best policy action (self.get_best_action).\n",
        "\n",
        "        Note: To pick randomly from a list, use random.choice(list). \n",
        "              To pick True or False with a given probablity, generate uniform number in [0, 1]\n",
        "              and compare it with your probability\n",
        "        \"\"\"\n",
        "\n",
        "        # Pick Action\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "        best_action = self.get_best_action(state)\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        # agent parameters:\n",
        "        epsilon = self.epsilon\n",
        "\n",
        "        probs = [epsilon/(len(possible_actions)-1) if action!=best_action else 1-epsilon for action in possible_actions]\n",
        "        chosen_action = np.random.choice(possible_actions, p=probs)\n",
        "\n",
        "        return chosen_action"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9FqXzcaiiuP"
      },
      "source": [
        "Now we gonna implement Expected Value SARSA on top of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqqvYz2yiiuQ"
      },
      "source": [
        "class EVSarsaAgent(QLearningAgent):\n",
        "    \"\"\" \n",
        "    An agent that changes some of q-learning functions to implement Expected Value SARSA. \n",
        "    Note: this demo assumes that your implementation of QLearningAgent.update uses get_value(next_state).\n",
        "    If it doesn't, please add\n",
        "        def update(self, state, action, reward, next_state):\n",
        "            and implement it for Expected Value SARSA's V(s')\n",
        "    \"\"\"\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\" \n",
        "        Returns Vpi for current state under epsilon-greedy policy:\n",
        "          V_{pi}(s) = sum _{over a_i} {pi(a_i | s) * Q(s, a_i)}\n",
        "\n",
        "        Hint: all other methods from QLearningAgent are still accessible.\n",
        "        \"\"\"\n",
        "        epsilon = self.epsilon\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        if len(possible_actions) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        best_action = self.get_best_action(state)\n",
        "\n",
        "        state_value = 0\n",
        "\n",
        "        for action in possible_actions:\n",
        "\n",
        "            if action != best_action:\n",
        "                prob = epsilon/len(possible_actions)\n",
        "            else:\n",
        "                prob = (1-epsilon) + epsilon/len(possible_actions)\n",
        "\n",
        "            state_value += prob * self.get_qvalue(state, action)\n",
        "\n",
        "        return state_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX_ijeNLiiuR"
      },
      "source": [
        "### Cliff World\n",
        "\n",
        "Let's now see how our algorithm compares against q-learning in case where we force agent to explore all the time.\n",
        "\n",
        "<img src=https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/cliffworld.png width=600>\n",
        "<center><i>image by cs188</i></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQYnlC_4iiuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8202314-55a6-473b-d25f-c332c040c3b4"
      },
      "source": [
        "import gym\n",
        "import gym.envs.toy_text\n",
        "env = gym.envs.toy_text.CliffWalkingEnv()\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "print(env.__doc__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "    This is a simple implementation of the Gridworld Cliff\n",
            "    reinforcement learning task.\n",
            "\n",
            "    Adapted from Example 6.6 (page 106) from Reinforcement Learning: An Introduction\n",
            "    by Sutton and Barto:\n",
            "    http://incompleteideas.net/book/bookdraft2018jan1.pdf\n",
            "\n",
            "    With inspiration from:\n",
            "    https://github.com/dennybritz/reinforcement-learning/blob/master/lib/envs/cliff_walking.py\n",
            "\n",
            "    The board is a 4x12 matrix, with (using Numpy matrix indexing):\n",
            "        [3, 0] as the start at bottom-left\n",
            "        [3, 11] as the goal at bottom-right\n",
            "        [3, 1..10] as the cliff at bottom-center\n",
            "\n",
            "    Each time step incurs -1 reward, and stepping into the cliff incurs -100 reward\n",
            "    and a reset to the start. An episode terminates when the agent reaches the goal.\n",
            "    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Il359aEiiuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac26c0b5-fa7c-4a5e-e07f-a89e64c14fd6"
      },
      "source": [
        "# Our cliffworld has one difference from what's on the image: there is no wall.\n",
        "# Agent can choose to go as close to the cliff as it wishes. x:start, T:exit, C:cliff, o: flat ground\n",
        "env.render()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "x  C  C  C  C  C  C  C  C  C  C  T\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC6G4RtviiuS"
      },
      "source": [
        "def play_and_train(env, agent, t_max=10**4):\n",
        "    \"\"\"This function should \n",
        "    - run a full game, actions given by agent.getAction(s)\n",
        "    - train agent using agent.update(...) whenever possible\n",
        "    - return total reward\"\"\"\n",
        "    total_reward = 0.0\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        a = agent.get_action(s)\n",
        "\n",
        "        next_s, r, done, _ = env.step(a)\n",
        "        agent.update(s, a, r, next_s)\n",
        "\n",
        "        s = next_s\n",
        "        total_reward += r\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    return total_reward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmCj3LCviiuU"
      },
      "source": [
        "agent_sarsa = EVSarsaAgent(alpha=0.25, epsilon=0.1, discount=0.99,\n",
        "                           get_legal_actions=lambda s: range(n_actions))\n",
        "\n",
        "agent_ql = QLearningAgent(alpha=0.25, epsilon=0.1, discount=0.99,\n",
        "                          get_legal_actions=lambda s: range(n_actions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpwIr14fiiuU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "78f207e0-2ccc-45c8-c823-0b22ce26272a"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "\n",
        "def moving_average(x, span=100):\n",
        "    return pd.DataFrame({'x': np.asarray(x)}).x.ewm(span=span).mean().values\n",
        "\n",
        "rewards_sarsa, rewards_ql = [], []\n",
        "\n",
        "for i in range(5000):\n",
        "    rewards_sarsa.append(play_and_train(env, agent_sarsa))\n",
        "    rewards_ql.append(play_and_train(env, agent_ql))\n",
        "    # Note: agent.epsilon stays constant\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(True)\n",
        "        print('EVSARSA mean reward =', np.mean(rewards_sarsa[-100:]))\n",
        "        print('QLEARNING mean reward =', np.mean(rewards_ql[-100:]))\n",
        "        plt.title(\"epsilon = %s\" % agent_ql.epsilon)\n",
        "        plt.plot(moving_average(rewards_sarsa), label='ev_sarsa')\n",
        "        plt.plot(moving_average(rewards_ql), label='qlearning')\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.ylim(-500, 0)\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EVSARSA mean reward = -26.91\n",
            "QLEARNING mean reward = -68.83\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJt9jL_BiiuV"
      },
      "source": [
        "Let's now see what did the algorithms learn by visualizing their actions at every state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXKodpyziiuV"
      },
      "source": [
        "def draw_policy(env, agent):\n",
        "    \"\"\" Prints CliffWalkingEnv policy with arrows. Hard-coded. \"\"\"\n",
        "    n_rows, n_cols = env._cliff.shape\n",
        "\n",
        "    actions = '^>v<'\n",
        "\n",
        "    for yi in range(n_rows):\n",
        "        for xi in range(n_cols):\n",
        "            if env._cliff[yi, xi]:\n",
        "                print(\" C \", end='')\n",
        "            elif (yi * n_cols + xi) == env.start_state_index:\n",
        "                print(\" X \", end='')\n",
        "            elif (yi * n_cols + xi) == n_rows * n_cols - 1:\n",
        "                print(\" T \", end='')\n",
        "            else:\n",
        "                print(\" %s \" %\n",
        "                      actions[agent.get_best_action(yi * n_cols + xi)], end='')\n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaoJY9UkiiuV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b553b65c-c863-4b7e-c714-ab27551d594a"
      },
      "source": [
        "print(\"Q-Learning\")\n",
        "draw_policy(env, agent_ql)\n",
        "\n",
        "print(\"SARSA\")\n",
        "draw_policy(env, agent_sarsa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q-Learning\n",
            " v  >  >  v  v  >  >  v  v  v  v  v \n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " X  C  C  C  C  C  C  C  C  C  C  T \n",
            "SARSA\n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " ^  ^  ^  ^  ^  ^  ^  ^  ^  ^  >  v \n",
            " X  C  C  C  C  C  C  C  C  C  C  T \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP54eE5giiuW"
      },
      "source": [
        "### Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-niuUrWxiiuW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "087e3395-307f-4573-f204-3383b1f900a0"
      },
      "source": [
        "from submit import submit_sarsa\n",
        "submit_sarsa(rewards_ql, rewards_sarsa, 'your.email@example.com', 'YourAssignmentToken')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTZoZtkMiiuX"
      },
      "source": [
        "### More\n",
        "\n",
        "Here are some of the things you can do if you feel like it:\n",
        "\n",
        "* Play with epsilon. See learned how policies change if you set epsilon to higher/lower values (e.g. 0.75).\n",
        "* Expected Value SASRSA for softmax policy:\n",
        "$$ \\pi(a_i|s) = softmax({Q(s,a_i) \\over \\tau}) = {e ^ {Q(s,a_i)/ \\tau}  \\over {\\sum_{a_j}  e ^{Q(s,a_j) / \\tau }}} $$\n",
        "* Implement N-step algorithms and TD($\\lambda$): see [Sutton's book](http://incompleteideas.net/book/bookdraft2018jan1.pdf) chapter 7 and chapter 12.\n",
        "* Use those algorithms to train on CartPole in previous / next assignment for this week."
      ]
    }
  ]
}